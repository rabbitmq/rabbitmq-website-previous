<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><meta name="description" content="RabbitMQ is a complete and highly reliable enterprise messaging system based on the emerging AMQP standard" /><meta name="googlebot" content="NOODP" /><meta name="google-site-verification" content="nSYeDgyKM9mw5CWcZuD0xu7iSWXlJijAlg9rcxVOYf4" /><meta name="google-site-verification" content="6UEaC3SWhpGQvqRnSJIEm2swxXpM5Adn4dxZhFsNdw0" /><link rel="stylesheet" href="/v3_0_x/css/rabbit.css" type="text/css" /><style xmlns:html="http://www.w3.org/1999/xhtml" xmlns:doc="http://www.rabbitmq.com/namespaces/ad-hoc/doc">
    body { 
    background: 
    url(/v3_0_x/img/previous-bg.png);
   }
  </style><link rel="icon" type="/image/vnd.microsoft.icon" href="/v3_0_x/favicon.ico" /><link rel="stylesheet" href="/v3_0_x/css/tutorial.css" type="text/css" /><script type="text/javascript" src="/v3_0_x/js/site.js"></script><script type="text/javascript" src="/v3_0_x/js/ga-bootstrap.js"></script><title>RabbitMQ - Clustering and Network Partitions</title>
    
  </head>
  <body><div id="outerContainer"><div id="rabbit-logo"><a href="/v3_0_x/"><img src="/v3_0_x/img/rabbitmq_logo_strap.png" alt="RabbitMQ" width="253" height="53" /></a></div><div id="vmw-logo"><a href="http://www.vmware.com/"><img src="/v3_0_x/img/vmw_logo_09q3.png" alt="VMware" width="118" height="18" /></a></div><div id="nav-search"><ul class="mainNav"><li><a href="/v3_0_x/download.html">Installation</a></li><li><a href="/v3_0_x/documentation.html" class="selected">Documentation</a></li><li><a href="/v3_0_x/getstarted.html">Tutorials</a></li><li><a href="/v3_0_x/services.html">Services</a></li><li><a href="/v3_0_x/community.html">Community</a></li></ul></div><div class="nav-separator"></div><div id="left-content"><h1>Clustering and Network Partitions</h1>
    <p>
      RabbitMQ clusters do not tolerate network partitions well. If
      you are thinking of clustering across a WAN, don't. You should
      use <a href="federation.html">federation</a> or
      the <a href="shovel.html">shovel</a> instead.
    </p>
    <p>
      However, sometimes accidents happen. This page documents how
      to detect network partitions, some of the bad effects that may
      happen during partitions, and how to recover from them.
    </p>
    <p>
      RabbitMQ stores information about queues, exchanges, bindings
      etc in Erlang's distributed database, <i>Mnesia</i>. Many of
      the details of what happens around network partitions are
      related to Mnesia's behaviour.
    </p>

    <h2>Detecting network partitions</h2>
    <p>
      Mnesia will typically determine that a node is down if another
      node is unable to contact it for a minute or so (see the section
      on <span class="code ">net_ticktime</span> below). If two nodes come back into
      contact, both having thought the other is down, Mnesia will
      determine that a partition has occured. This will be written to
      the RabbitMQ log in a form like:
    </p>
    <pre>=ERROR REPORT==== 15-Oct-2012::18:02:30 ===
Mnesia(rabbit@smacmullen): ** ERROR ** mnesia_event got
    {inconsistent_database, running_partitioned_network, hare@smacmullen}</pre>
    <p>
      RabbitMQ nodes will record whether this event has ever occured
      while the node is up, and expose this information
      through <span class="code ">rabbitmqctl cluster_status</span> and the
      management plugin.
    </p>
    <p>
      <span class="code ">rabbitmqctl cluster_status</span> will normally show an
      empty list for <span class="code ">partitions</span>:
    </p>
    <pre># rabbitmqctl cluster_status
Cluster status of node rabbit@smacmullen ...
[{nodes,[{disc,[hare@smacmullen,rabbit@smacmullen]}]},
 {running_nodes,[rabbit@smacmullen,hare@smacmullen]},
 {partitions,[]}]
...done.</pre>
    <p>
      However, if a network partition has occured then information
      about partitions will appear there:
    </p>
    <pre># rabbitmqctl cluster_status
Cluster status of node rabbit@smacmullen ...
[{nodes,[{disc,[hare@smacmullen,rabbit@smacmullen]}]},
 {running_nodes,[rabbit@smacmullen,hare@smacmullen]},
 {partitions,[{rabbit@smacmullen,[hare@smacmullen]},
              {hare@smacmullen,[rabbit@smacmullen]}]}]
...done.</pre>
    <p>
      The management plugin API will return partition
      information for each node under <span class="code ">partitions</span>
      in <span class="code ">/api/nodes</span>. The management plugin UI will show a
      large red warning on the overview page if a partition has
      occured.
    </p>

    <h2>During a network partition</h2>
    <p>
      While a network partition is in place, the two (or more!) sides
      of the cluster can evolve independently, with both sides
      thinking the other has crashed. Queues, bindings, exchanges can
      be created or deleted separately. <a href="ha.html">Mirrored
      queues</a> which are split across the partition will end up with
      one master on each side of the partition, again with both sides
      acting independently. Other undefined and weird behaviour may
      occur.
    </p>
    <p>
      <b>It is important to understand that when network connectivity
      is restored, this state of affairs persists. The cluster
      will continue to act in this way until you take action to
      fix it.</b>
    </p>

    <h2>Recovering from a network partition</h2>
    <p>
      To recover from a network partition, first choose one partition
      which you trust the most. This partition will become the
      authority for the state of Mnesia to use; any changes which have
      occured on other partitions will be lost.
    </p>
    <p>
      Stop all nodes in the other partitions, then start them all up
      again. When they rejoin the cluster they will restore state from
      the trusted partition.
    </p>
    <p>
      Finally, you should also restart all the nodes in the trusted
      partition to clear the warning.
    </p>
    <p>
      It may be simpler to stop the whole cluster and start it again;
      if so make sure that the <b>first</b> node you start is from the
      trusted partition.
    </p>
    <h2 id="net_ticktime">net_ticktime</h2>
    <p>
      The initial determination that a node is down is made by the
      Erlang virtual machine. This is controlled by
      the <span class="code ">net_ticktime</span> parameter to
      the <span class="code ">kernel</span> application,
      documented <a href="http://erlang.org/doc/man/kernel_app.html">here</a>.
    </p>
    <p>
      It is possible that you may want to increase
      the <span class="code ">net_ticktime</span> value to cover up short-lived
      network outages. You could do so with a configuration file
      looking like:
    </p>
    <pre>[{kernel, [{net_ticktime, 120}]}].</pre>
    <p>
      which would increase the ticktime from 60 seconds to 120 seconds.
    </p>
    <p>
      Conversely, you may wish to decrease the value in order to
      detect network outages more promptly.
    </p>
    <p>
      But be aware that there is no free lunch here: by increasing the
      ticktime you also increase the length of time that RabbitMQ may
      be unresponsive, waiting for a reply from a cluster node which
      has gone down or lost connectivity. Conversely, decreasing the
      ticktime can result in nodes being detected as dead when in fact
      they are still alive and reachable but perhaps busy. Adjusting
      the <span class="code ">net_ticktime</span> is <b>not</b> a general solution
      to the problem of network partitions.
    </p>
  </div><div id="right-nav"><div id="in-this-section"><h4>In This Section</h4><ul>
     <li><a href="/v3_0_x/features.html">Features</a></li>
     <li><a href="/v3_0_x/admin-guide.html" class="selected">Server Documentation</a><ul>
       <li><a href="/v3_0_x/configure.html">Configuration</a></li>
       <li><a href="/v3_0_x/ssl.html">SSL Support</a></li>
       <li><a href="/v3_0_x/distributed.html">Distributed RabbitMQ</a></li>
       <li><a href="/v3_0_x/reliability.html">Reliable Delivery</a></li>
       <li><a href="/v3_0_x/clustering.html" class="selected">Clustering</a><ul>
         <li><a href="/v3_0_x/partitions.html" class="selected">Network Partitions</a></li>
       </ul></li>
       <li><a href="/v3_0_x/ha.html">High Availability</a></li>
       <li><a href="/v3_0_x/pacemaker.html">High Availability (pacemaker)</a></li>
       <li><a href="/v3_0_x/access-control.html">Access Control</a></li>
       <li><a href="/v3_0_x/authentication.html">SASL Authentication</a></li>
       <li><a href="/v3_0_x/memory.html">Flow Control</a></li>
       <li><a href="/v3_0_x/memory-use.html">Memory Use</a></li>
       <li><a href="/v3_0_x/firehose.html">Firehose / Tracing</a></li>
       <li><a href="/v3_0_x/manpages.html">Manual Pages</a></li>
       <li><a href="/v3_0_x/windows-quirks.html">Windows Quirks</a></li>
       
       
       
       
     </ul></li>
     <li><a href="/v3_0_x/clients.html">Client Documentation</a></li>
     <li><a href="/v3_0_x/plugins.html">Plugins</a></li>
     <li><a href="/v3_0_x/news.html">News</a></li>
     <li><a href="/v3_0_x/protocol.html">Protocol</a></li>
     <li><a href="/v3_0_x/extensions.html">Our Extensions</a></li>
     <li><a href="/v3_0_x/build.html">Building</a></li>
     <li><a href="/v3_0_x/mpl.html">License</a></li>
   </ul></div></div><div class="clear"></div><div class="pageFooter"><p class="righter"><a href="/v3_0_x/sitemap.html">Sitemap</a> |
        <a href="/v3_0_x/contact.html">Contact</a></p><p id="copyright">
        Copyright Â© 2013 VMware, Inc. All rights reserved.
        <a href="http://www.vmware.com/help/legal.html">Terms of Use</a> |
        <a href="http://www.vmware.com/help/privacy.html">Privacy</a></p></div></div></body>
</html>
